{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Visaulization Lecture 2: Jupyter Notebooks, Python Data Wrangling\n",
    "\n",
    "\n",
    "Welcome to your first Jupyter notebook! This will be our main working environment for this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebooks Basics\n",
    "\n",
    "First, let's get familiar with Jupyter Notebooks. \n",
    "\n",
    "Notebooks are made up of \"cells\" that can contain text or code. Notebooks also show you output of the code right below a code cell. These words are written in a text cell using a simple formatting dialect called [markdown](https://jupyterlab.readthedocs.io/en/latest/user/notebook.html). \n",
    "\n",
    "Double click on this cell text or press enter while the cell is selected to see how it is formatted and change it. We can make words *italic* or **bold** or add [links](https://www.dataviscourse.net/2023-applied/) or include pictures:\n",
    "\n",
    "![Data science cat](datasciencecat.jpg)\n",
    "\n",
    "The content of the notebook, as you edit in your browser, is written an `.ipynb` file. \n",
    "\n",
    "If you want to read up on Notebooks in details check out the [excellent documentation](https://jupyterlab.readthedocs.io/en/latest/index.html).\n",
    "\n",
    "## Notebook Editors\n",
    "\n",
    "Jupyter Notebooks can be edited and run in a number of ways. The easiest way is Jupyter Labs, a development environment explicitly made for notebooks. You can run labs using this command: \n",
    "\n",
    "```bash\n",
    "$ jupyter-lab\n",
    "```\n",
    "\n",
    "You then edit your notebook in the browser. \n",
    "\n",
    "The alternative we're using because of co-pilot support is to install **Visual Studio code**, the notebook extensions, and then edit there (see Homework 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "An alternative to native Jupyter Notebooks are cloud-hosted [google colab](https://colab.research.google.com/) notebooks; basically a cloud-based notebook solution that can read notebook files. Because it's cloud based, things like reading from files is different. For this class you should have the notbeooks installed locally, but google colab is a good alternative if you need to collaborate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Code\n",
    "\n",
    "The most interesting aspect of notebooks, however, is that we can write code in the cells. You can use [many different programming languages](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels) in Jupyter notebooks, but we'll stick to Python. So, let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Hello World!\")\n",
    "a = 3\n",
    "# the return value of the last line of a cell is the output\n",
    "a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output here is directly written into the notebook. \n",
    "\n",
    "You can change something in a cell and re-run it using the \"run cell\" button, or use the `CTRL+ENTER` (execute and remain in cell) or `SHIFT+ENTER` (execute and move to next cell) shortcut.\n",
    "\n",
    "Another cool thing about cells is that they preserve the state of what happened before. Let's initialize a couple of variables in the next cell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "age = 2\n",
    "gender = \"female\"\n",
    "name = \"Datascience Cat\"\n",
    "smart = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables are now available to all cell below or above **if you executed the cell**. In practice, you should never rely on a variable from a lower cell in an earlier cell. **This behavior is different from if you were to execute the cells as a python file.**\n",
    "\n",
    "If you make a change to a cell, you need to execute it again. You can also batch-executed multiple cells from the toolbar. \n",
    "\n",
    "Let's do something with the variables we just defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datascience Cat, age: 2, female, is smart: True\n"
     ]
    }
   ],
   "source": [
    "print (name + \", age: \" + str(age) + \", \" + \n",
    "       gender + \", is smart: \" + str(smart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cell, we've [concatenated a couple of strings](https://docs.python.org/3.5/tutorial/introduction.html#strings) to produce one longer string using the `+` operator. Also, we had to call the `str()` function to get [string representations of these variables](https://docs.python.org/3.5/library/stdtypes.html#str).\n",
    "\n",
    "We'll learn better ways to do this a bit later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modes\n",
    "\n",
    "Notebooks have two modes, a **command mode** and **edit mode**. These modes are shown differently in different notebook environments; in jupytper labs: \n",
    " * **green** means edit mode, \n",
    " * **blue** means command mode. \n",
    " \n",
    "Many operations depend on your mode. For code cells, you can switch into edit mode with \"Enter\", and get out of it with \"Escape\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Shortucts\n",
    "\n",
    "While you can always use the tool-bar above, you'll be much more efficient if you use a couple of shortcuts. The most important ones are:\n",
    "\n",
    "**`Ctrl+Enter`** runs the current cell.  \n",
    "**`Shift+Enter`** runs the current cell and jumps to the next cell.   \n",
    "**`Alt+Enter`** runs the cell and adds a new one below it.\n",
    "\n",
    "In command mode:\n",
    "\n",
    "**`h`** shows a help menu with all these commands (doesn't work in visual studio).  \n",
    "**`a`** adds a cell before the current cell.  \n",
    "**`b`** adds a cell after the current cell.  \n",
    "**`dd`** deletes a cell.  \n",
    "**`m`** as in **m**arkdown, switches a cell to markdown mode.  \n",
    "**`y`** as in p**y**thon switches a cell to code.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels\n",
    "\n",
    "When you [run code](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Running%20Code.html), the code is actually executed in a **kernel**. You can do bad things to a kernel: you can make it stuck in an endless loop, crash it, corrupt it, etc. And you probably will do all of these things :). \n",
    "\n",
    "So sometimes you might have to interrupt your kernel or restart it. \n",
    "\n",
    "Also, before submitting a homework or a project, make sure to `Restart` and `Run All`. This will create a clean run of your project, without any side effects that you might encounter during development. We want you to submit the homeworks **with output**, and by doing that you will make sure that we actually can also execute your code properly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Storing Output\n",
    "\n",
    "Notebooks contain both, the input to a computation and the outputs. If you run a notebook, all the outputs generated by the code cells are also stored in the notebook. That way, you can look at notebooks also in non-interactive environments, like on [GitHub for this notebook](https://github.com/dataviscourse/2023-applied-vis-homeworks/blob/main/HW0/notebook-demo.ipynb). \n",
    "\n",
    "The Notebook itself is stored in a rather ugly format containing the text, code, and the output. This can sometimes be challenging when working with version control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Basics\n",
    "\n",
    "## Functions\n",
    "\n",
    "In math, functions transfrom an input to an output as defined by the property of the function. \n",
    "\n",
    "You probably remember functions defined like this\n",
    "\n",
    "$f(x) = x^2 + 3$\n",
    "\n",
    "In programming, functions can do exactly this, but are also used to execute “subroutines”, i.e., to execute pieces of code in various order and under various conditions. Functions in programming are very important for structuring and modularizing code. \n",
    "\n",
    "In computer science, functions are also called “procedures” and “methods” (there are subtle distinctions, but nothing we need to worry about at this time). \n",
    "\n",
    "The following Python function, for example, provides the output of the above defined function for every valid input: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    result = x ** 2 + 3 \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run this function with multiple input values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f(2))\n",
    "print(f(3))\n",
    "f(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at this function. The first line\n",
    "```python\n",
    "def f(x):\n",
    "```\n",
    "defines the function of name `f` using the `def` keyword. The name we use (`f` here) is largely arbitrary, but following good software engineering practices it should be something meaningful. So instead of `f`, **`square_plus_three` would be a better function name in this case**.  \n",
    "\n",
    "After the function name follows a list of parameters, in parantheses. In this case we define that the function takes only one parameter, `x`, but we could also define multiple parameters like this:\n",
    "```python \n",
    "def f(x, y, z):\n",
    "```\n",
    "\n",
    "The parameters are then available as local variables within the function.\n",
    "\n",
    "The second line does the actual computation and assigns it to a **local variable** called `result`. \n",
    "\n",
    "The third line uses the `return` keyword to return the result variable. Functions can have a return value that we can assign to a variable. For example, here we could write: \n",
    "\n",
    "```python\n",
    "my_result = f(10)\n",
    "``` \n",
    "\n",
    "Which would assign the return value of the function to the variable `my_result`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the lines of code that belong to a function are **intended by four spaces** (you can hit tab to intend, but it will be converted to four spaces). Python defines the scope of a function using intendation. Many other programming languages use curly brackets `{}` to do this. \n",
    "\n",
    "A function is ended by a new line.\n",
    "\n",
    "For example, the same function wouldn't work like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (562016350.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    return result\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    result = x ** 2 + 3\n",
    "# Throws a NameError becauser result isn't defined outside the function\n",
    "return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll take a look at a compound data type: [lists](https://docs.python.org/3/tutorial/introduction.html#lists).\n",
    "\n",
    "**A list is a collection of items.** Another word commonly used for a list in other programming languages is an **array** (though there are differences between lists and arrays in many languages). \n",
    "\n",
    "**Lists are created with square brackets `[]` and can be accessed via an index:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0-Paul', '1-John', '2-George', '3-Ringo']\n",
      "0-Paul\n",
      "2-George\n",
      "3-Ringo\n",
      "2-George\n"
     ]
    }
   ],
   "source": [
    "beatles = [\"0-Paul\", \"1-John\", \"2-George\", \"3-Ringo\"]\n",
    "# printing the whole array\n",
    "print(beatles)\n",
    "# printing the first element of that array, at index 0\n",
    "print(beatles[0])\n",
    "# third element, at index 2\n",
    "print(beatles[2])\n",
    "# access the last element\n",
    "print(beatles[-1])\n",
    "# access the one-but-last element\n",
    "print(beatles[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to address an index outside of the range of an array, we get an error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m beatles[\u001b[39m4\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "beatles[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, it makes sense to pre-initialize an array of a certain size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0] * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a handy shortcut for quickly initializing lists. This uses the [range()](https://docs.python.org/3/library/functions.html#func-range) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create **slices of an array with the slice operator `:`**\n",
    "\n",
    "```python\n",
    "a[start:end] # items start through end-1\n",
    "a[start:]    # items start through the rest of the array\n",
    "a[:end]      # items from the beginning through end-1\n",
    "a[:]         # a copy of the whole array\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also the step value, which can be used with any of the above:\n",
    "\n",
    "```python\n",
    "a[start:end:step] # start through not past end, by step\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [this post](http://stackoverflow.com/questions/509211/explain-pythons-slice-notation) for a good explanation on slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-Paul', '1-John']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the slice from 0 (included) to 2 (excluded)\n",
    "beatles[:2] # this can also be written as [0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-George', '3-Ringo']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sclice from index 2 (3rd element) to end\n",
    "beatles[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-Paul', '1-John', '2-George', '3-Ringo']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A copy of the array \n",
    "beatles[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slice operations return a new array, the original array is untouched: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-Paul', '1-John', '2-George', '3-Ringo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing outside of a defined range returns an empty list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles[4:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists (in contrast to strings) are mutable. \n",
    "\n",
    "That means **we can change the elements that are contained in a list**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-Paul', '1-JohnYoko', '2-George', '3-Ringo']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles[1] = \"1-JohnYoko\"\n",
    "beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays can also be **extended with the `append()` function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-Paul', '1-JohnYoko', '2-George', '3-Ringo', '4-George Martin']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles.append(\"4-George Martin\")\n",
    "beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists can be **concatenated**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-Paul',\n",
       " '1-JohnYoko',\n",
       " '2-George',\n",
       " '3-Ringo',\n",
       " '4-George Martin',\n",
       " 'Jimmy',\n",
       " 'Robert',\n",
       " 'John',\n",
       " 'John']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeppelin = [\"Jimmy\", \"Robert\", \"John\", \"John\"]\n",
    "supergroup = beatles + zeppelin\n",
    "supergroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **check the length** of a list using the built-in [`len()`](https://docs.python.org/3.3/library/functions.html#len) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zeppelin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists can also be **nested**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0-Paul', '1-JohnYoko', '2-George', '3-Ringo', '4-George Martin'],\n",
       " ['Jimmy', 'Robert', 'John', 'John']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands = [beatles, zeppelin]\n",
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, lists can be of hybrid data types, which, however, is something that you typically don't want to and shouldn't do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0-Paul', '1-JohnYoko', '2-George', '3-Ringo', '4-George Martin'],\n",
       " ['Jimmy', 'Robert', 'John', 'John'],\n",
       " 1,\n",
       " 0.3,\n",
       " 17,\n",
       " 'This is bad']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_bands = bands + [1, 0.3, 17, \"This is bad\"]\n",
    "# this list contains lists, integers, floats and strings\n",
    "bad_bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings\n",
    "\n",
    "Strings can be treated similar to arrays with respect to indexing and slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paul'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paul = \"Paul McCartney\"\n",
    "paul[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has very sophisticaed [methods for string manipulation](https://docs.python.org/3/library/string.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Paul', 'McCartney')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split based on a string; the return is a tuple\n",
    "firstname, lastname = paul.split(\" \")\n",
    "firstname, lastname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mccartney'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make lowercase\n",
    "lastname.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What's UP here\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove whitespaces from the beginning and end\n",
    "\"  What's UP here   \".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count occurences of a substring\n",
    "\"lalalala\".count(\"la\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More sophisticated searching/matching can be done with [regular expressions](https://docs.python.org/3/howto/regex.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strings can be assembled from different parts using various methods. The simplest one is the `+` operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paul McCartney'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Paul \" + \"McCartney\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use string formatting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first name of the artist is Paul, the second is McCartney'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The first name of the artist is {firstname}, the second is {lastname}\".format(firstname=firstname, lastname=lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or f-Strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first name of the artist is Paul, the second is McCartney'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The first name of the artist is {firstname}, the second is {lastname}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And obviously, we can do all the things we've learned about to this column/series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous example used columns to create the data frame. We can also create a data frame from rows. This doesn't make a ton of sense in this example, but data could be available like this from your data source, like if you're parsing a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandInfo2 = pd.DataFrame([\n",
    "        {\"Name\":\"Led Zeppelin\", \"No Albums\":9, \"No Members\":4},\n",
    "        {\"Name\":\"The Beatles\", \"No Albums\":12, \"No Members\":4},\n",
    "        {\"Name\":\"Rolling Stones\", \"No Albums\":29, \"No Members\":4},\n",
    "        {\"Name\":\"Radiohead\", \"No Albums\":9, \"No Members\":5},\n",
    "    ])\n",
    "bandInfo2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a series has only one axis, a dataframe has two, one for the rows (the index or '0' axis), one for the columns (the column or '1' axis). We can check out these axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandInfo.axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access these axes directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The row axis\n",
    "bandInfo.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns axis\n",
    "bandInfo.axes[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out the dimensions of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we learn that our dataset has 77 rows and 6 columns.\n",
    "\n",
    "We can also get more info about the dataset using the info method, which is especially helpful to see the data types of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for series, we can get a rough description of the numerical values of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see any descriptions of the columns of non-numerical type. We can, however, get a summary by directly accessing a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[\"Artist\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that Michael Jackson is the top artist in this list, with five albums. Are there other artists with multiple albums in the list? We can answer that question with the value_counts() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[\"Artist\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at whether the numerical columns in our data frame are correlated using the [`corr()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) method. By default, this calculates a Pearson correlation between the column, excluding NaN values. Not surprisingly, we see a rather strong correlation (0.81) between certified and claimed sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do transpose a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing Data Frames\n",
    "\n",
    "A common task is to create subsets of a dataframe. Check out the official [user guide for more info on this](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html).  \n",
    "\n",
    "Column access/slicing works by directly using brackets `[]` on the data frame. Row access/slicing works by using the `.loc[]` indexer. \n",
    "\n",
    "We can explicitly define the the **column(s)** we want by their lables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single column\n",
    "hit_albums[\"Artist\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an array of lables if we want multiple columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying multiple columns in an array\n",
    "hit_albums = hit_albums[[\"Artist\",\"Certified sales (millions)\", \"Claimed sales (millions)\"]]\n",
    "hit_albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing of columns requires the `iloc` operator\n",
    "\n",
    "This: \n",
    "```python\n",
    "hit_albums[\"Artist\":\"Genre\"]\n",
    "```\n",
    "Doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One break with the convention that rows have to be accessed via `loc` or `iloc` is simple numerical slicing. The documentation claims that's for convenience, since this is so common: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these access methods we can also update the order: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[[\"Certified sales (millions)\", \"Claimed sales (millions)\", \"Artist\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set a column to be the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed = hit_albums.set_index(\"Artist\")\n",
    "hit_albums_reindexed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing with `loc`\n",
    "\n",
    "We can retrieve **rows** and columns using the `loc` indexer by name. Depending on whether the label is unique or not, we get either a series or a data frame. \n",
    "\n",
    "Generally, `loc` is preferred over direct access via brackets. \n",
    "\n",
    "The general syntax is\n",
    "\n",
    "```\n",
    "df.loc[rows, columnns]\n",
    "```\n",
    "Here rows, columns can be explicit labels, lists of labels, or slicing operators. \n",
    "\n",
    "Here's a simple example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Meat Loaf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an example with multiple keys that returns a data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Michael Jackson\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second argument in the `loc` array can be used to access columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Michael Jackson\", \"Certified sales (millions)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example with a list of row labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[[\"Michael Jackson\", \"Meat Loaf\"], \"Certified sales (millions)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use slice operations. Remember, that slicing by label (`loc`) includes the last value, by index (`iloc`) does not. \n",
    "\n",
    "\n",
    "Note that this doesn't work if we use labels that have duplicates as indexers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Green Day\":\"Supertramp\"]\n",
    "\n",
    "# this wouldn't work\n",
    "# hit_albums_reindexed.loc[\"Green Day\":\"Michael Jackson\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be combined with slicing columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Green Day\":\"Supertramp\", [\"Certified sales (millions)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also slice columns with loc. Let's re-load the full dataset first:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums = pd.read_csv(\"hit_albums.csv\")\n",
    "full_hit_albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a slice containing all rows and the columns from Artist to Released: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[:,\"Artist\":\"Released\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a slice for the first 10 rows and columns Artists to Released: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[:10,\"Artist\":\"Released\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same thing using `iloc`, i.e., index based slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.iloc[0:10, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Of course, we can use broadcasting and filtering based on boolean masks just as we do for series.\n",
    "\n",
    "Here we boradcast an operation on a series and set it to a new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums[\"Certified sales\"] =  full_hit_albums[\"Certified sales (millions)\"] * 1000000\n",
    "full_hit_albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we filter out all of the albums that were released before 1990. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = full_hit_albums[\"Released\"] > 1990\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, short: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[full_hit_albums[\"Released\"] > 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Data Frames\n",
    "\n",
    "Very often, we want to aggregate data. Given the hit-albums dataset, for example, we might want to ask how many albums each artist in that list has sold in total. We can do these aggregations using the [group-by method](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html). \n",
    "\n",
    "But first, let's take care of some NAN values by running [`fillna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) on it. We use forward fill along the columns, so that the certified sales are filled into the claimed sales if necessary. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums = hit_albums.fillna(axis=1, method='ffill')\n",
    "hit_albums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a column to group by, for example, \"Artist\". We can look at the groups created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = hit_albums.groupby(\"Artist\")\n",
    "grouped.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the keys map to a set of indices. For example, Michael Jackson's albums are found at indices [0, 10, 16, 65, 66].\n",
    "\n",
    "Once we have created these groups, we can specify what to do with it.\n",
    "\n",
    "Pandas has a couple of built in functions to make this easy. For example, we can just call `sum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sum().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that we've summed up the data for each column. However, note that NaN plus some number is still NaN, which is treated as 0 here. So let's work with a slice of the dataframe instead. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we sort them, and have a nice result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sum().sort_values(\"Certified sales (millions)\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is the `count` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.count().sort_values(\"Certified sales (millions)\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A very generic solution is the `agg()` function, which we can pass a function to do things with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we pass the sum function, which calcualtes the sum of a list, to the group\n",
    "grouped.agg(sum).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass in numpy functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "grouped.agg(np.std).sort_values(\"Certified sales (millions)\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an aggregation with an in-line function definition where we still create the sum, but also multiply by a million. We use a [lambda expression](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions) to define the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg(lambda rows : sum([cell * 1000000 for cell in rows])).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda expressions are just a different way of defining a function in line, without assigning it a name. They only work for a single statement. \n",
    "\n",
    "Here is a simple lambda expression, which returns a function, which we assign to the variable add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = lambda a, b : a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's take this apart: \n",
    "\n",
    "```python\n",
    "[cell * 1000000 for cell in rows]\n",
    "```\n",
    "\n",
    "This part is a list comprehension, that takes an array `rows` and multiplies every element with 1,000,000. \n",
    "\n",
    "The surrounding `sum` is a call to the sum function, so adds up the values in the just modified array. \n",
    "\n",
    "And finally, the lambda expression packs all of this in a function. \n",
    "\n",
    "Here is a different, longer way to write this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumUpAndMultiplyByMillion(rows):\n",
    "    multiplied_rows = [cell * 1000000 for cell in rows]\n",
    "    summed_value = sum(multiplied_rows)\n",
    "    return summed_value\n",
    "\n",
    "grouped.agg(sumUpAndMultiplyByMillion).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Data Frames\n",
    "\n",
    "* Calculate the mean certified sales for all albums.\n",
    "* Create a new dataframe that only contains albums with more than 20 million certified sales.\n",
    "* Create a new dataframe based on the hit_albums dataset that only contains the artists that have at least two albums in the list.\n",
    "* Create a new dataframe that contains the aggregates sum of all certified sales for each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buit-in Plotting\n",
    "\n",
    "Dataframes have built-in plotting capabilities based on the [matplotlib](http://matplotlib.org/) library. We'll see more about plotting later - here we'll only use the buit-in capabilities of pandas. \n",
    "\n",
    "First, we have to import the matplotlib library, and tell Jupyter to display the images directly here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "# This next line tells jupyter to render the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can simply call the plot attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also selected certain columns using labelled indexes and then plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[\"Certified sales (millions)\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use bar-charts instead of line-charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[[\"Certified sales (millions)\", \"Claimed sales (millions)\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is a line chart. This doesn't make much sense, since it's mixing index of the row with sales. We're better off plotting only the two different sales figures.\n",
    "\n",
    "A better way to compare certified and claimed sales is a scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is currently broken due to a pandas bug. \n",
    "# hit_albums.plot.scatter(x=\"Certified sales (millions)\", y=\"Claimed sales (millions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a histogram: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.plot.hist(bins=12, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do more sophisticated plotting next time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Lists\n",
    "\n",
    "We will frequently use [NumPy](https://numpy.org/) arrays instead of regular Python lists. NumPy provides data structures and operations that are suitable, especially with regards to performance, for scientific computing.\n",
    "\n",
    "Here's a simple NumPy array. We can do slicing etc just like on regular arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "my_array = np.array([1,2,3,4,5])\n",
    "\n",
    "print(my_array[1])\n",
    "print(my_array[-1])\n",
    "print(my_array[1:3])\n",
    "# Notice that the data type is different from a regular python data type\n",
    "print(my_array.dtype.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays have a lot of additional functionality, which we will introduce as needed. One significant difference to regular arrays is that an array has to be of a single data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to set up a hybrid array; that would be OK in python lists. \n",
    "my_hybrid_array = np.array([1,\"test\",3,4,5])\n",
    "\n",
    "# We see that the elements are up-casted to the most inclusive data type, a string.\n",
    "print(my_hybrid_array)\n",
    "print(type(my_hybrid_array[-1]))\n",
    "print(my_hybrid_array.dtype.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[List comprehension](https://docs.python.org/3.5/tutorial/datastructures.html#list-comprehensions) is a very \"pythonic\" method for manipulating data. List comprehension can be used to initialize and transform arrays. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ is customary for a variable name if you don't need it\n",
    "[0 for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"John\" for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also make  use of values we iterate over\n",
    "[i for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, for example, use functions in place of a variable. Here we initialize an array of random numbers in the unit interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rands = [random.random() for _ in range(10)]\n",
    "rands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use list comprehension to create a list based on another list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x*10 for x in rands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists can be **concatenated**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeppelin = [\"Jimmy\", \"Robert\", \"John\", \"John\"]\n",
    "beatles += zeppelin\n",
    "beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **check the length** of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zeppelin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists can also be **nested**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's reset the beatles first\n",
    "beatles = [\"Paul\", \"John\", \"George\", \"Ringo\"]\n",
    "bands = [beatles, zeppelin]\n",
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules are used, ugh, to modularize code. You can write a module by simply creating a `.py` file. We won't be writing many modules ourselves, but we will use them extensively.\n",
    "\n",
    "To import a module simply write\n",
    "\n",
    "```python\n",
    "import module_name\n",
    "```\n",
    "\n",
    "You can then use functions defined in the module with the `.` notation. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `from` notation to import specific functions from a package and add them directly to the namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "# notice that this is NOT accessed via math.log10()\n",
    "log10(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also bulk-import all functions of a module into your local namespace, however, this is **strongly discouraged**, as it can lead to name-clashes and makes your code unreadable eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import * \n",
    "log2(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can redefine the name of a module. This is useful to define a shorthand for long library names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m \n",
    "m.sqrt(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pandas Library: Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a popular library for manipulating vectors, tables, and time series. We will frequently use Pandas data structures instead of the built-in python data structures, as they provide much richer functionality. Also, Pandas is **fast**, which makes working with large datasets easier.  Check out the official pandas website at [http://pandas.pydata.org/](http://pandas.pydata.org/).\n",
    "\n",
    "This tutorial is partially based on the [excellent book by Matt Harrison](https://www.amazon.com/Learning-Pandas-Library-Analysis-Visualization-ebook/dp/B01GIE03GW/).\n",
    "\n",
    "When you work with Pandas, it's handy to have a [cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) lying around. \n",
    "\n",
    "Pandas provides three data structures: \n",
    "\n",
    " * the **series**, which represents a single column of data similar to a python list\n",
    " * the **data frame**, which represents multiple series of data\n",
    " * the **panel**, which represents multiple data frames\n",
    " \n",
    "We'll mostly work with series and data frames and largely ignore panels. Today we will stick to series. \n",
    "\n",
    "Pandas should already be part of your anaconda installation. If not, simply run:\n",
    "\n",
    "```\n",
    "$ conda install pandas\n",
    "```\n",
    "\n",
    "To make pandas available, we'll import the module into this notebook. It is customary to import pandas as `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series are the most fundamental data structure in pandas. Let's create two simple series based on an arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bands = pd.Series([\"Stones\", \"Beatles\", \"Zeppelin\", \"Pink Floyd\"])\n",
    "bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "founded = pd.Series([1962, 1960, 1968, 1965])\n",
    "founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we output these objects we can see an index, also called an axis, which by default is an integer sequence starting at 0, and the associated values. \n",
    "\n",
    "| Index | Value | \n",
    "| - | - |\n",
    "| 0  |        Stones\n",
    "|1   |    Beatles\n",
    "|2  |    Zeppelin\n",
    "|3 |    Pink Floyd\n",
    "\n",
    "Pandas also tells us the data type of the values, `object` for the first series – in this case, this is a string, `int64` (a 64-bit integer) for the second.\n",
    "\n",
    "Notice that `int64` is not a Python datatype, but a C integer of 64 bit length – which, unlike Python integers – can overflow!\n",
    "\n",
    "We can also use other data types as indices, in which case the series behaves a lot like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is the first parameter, the index is given by the index keyword\n",
    "bands_founded = pd.Series([1962, 1960, 1968, 1965, 2012],\n",
    "                          index=[\"Stones\", \"Beatles\", \"Zeppelin\", \"Pink Floyd\", \"Pink Floyd\"], \n",
    "                          name=\"Bands founded\")\n",
    "bands_founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Index | Value | \n",
    "| - | - |\n",
    "| Stones     |    1962\n",
    "| Beatles    |    1960\n",
    "| Zeppelin     |  1968\n",
    "| Pink Floyd |    1965\n",
    "| Pink Floyd |    2012\n",
    "\n",
    "Here we see something interesting: We've used the same index (Pink Floyd) twice, once for the original founding of the band, and once for the re-union starting in 2012. Also, the order of the entries is preserved. \n",
    "\n",
    "A series is both, a list and a dictionary! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the values of an array by printing the member `values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at how the index is composed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here is that this isn't an explicit list, but rather a set of rules, similar to the ranges we've already worked with. \n",
    "\n",
    "Let's compare this to the index where we used explicit labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access individual entries as we'd access an array or a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded[\"Beatles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a method for looking up a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.get(\"Stones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these access methods are as fast as a dictionary lookup, and much faster than a lookup in a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works also with arrays of labels, in which case the return type is a series, not a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.get([\"Stones\", \"Beatles\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we access data with multiple indices, we don't get a simple datatype, as in the above cases, but instead get another series back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded[\"Pink Floyd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series also have indexers for label-based access: [`loc`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And one more way for looking up a value:\n",
    "bands_founded.loc[\"Stones\"]\n",
    "# this is equivalent to \n",
    "# bands_founded[\"Stones\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related to the `loc` indexer is the [`iloc`](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.iloc.html) indexer. However, instead of operating on our label index, `iloc` operates purely on position: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an `ix` indexer, which is deprecated and should not be used.\n",
    "\n",
    "These ways of accessing slices of a dataset (`loc`, `iloc`), will make more sense when we use dataframes instead of series – in dataframes, `loc` and `iloc` operate on the rows, whereas square brackets operate on the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating\n",
    "\n",
    "Iteration works as you would expect: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in bands:\n",
    "    print(band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band, founded in bands_founded.items():\n",
    "    print(band + \", \" + str(founded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating\n",
    "Updating works largely as expected, however, you have to be careful when updating series with duplicate indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[2] = \"The Doors\"\n",
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a new item by direclty assigning it to a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[4] = \"Zeppelin\"\n",
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the indices don't have to be sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[17] = \"The Who\"\n",
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we update based on an index that occurs more than once, all instances are updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded[\"Pink Floyd\"] = 2015\n",
    "bands_founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to update a specific entry when an index is used multiple time is to use the `iloc` indexer. We can use the `iloc` array to set values based purely on position. However, all of this is rather ugly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.iloc[3] = 1965\n",
    "bands_founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting \n",
    "\n",
    "Deleting is rarely done with pandas data structures, instead filters and masks are used. It's possible based on indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bands_founded[\"Stones\"]\n",
    "bands_founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing\n",
    "\n",
    "Indexing and slicing works largely like in normal python, but instead of just directly using the bracket notations, it is recommended to use `iloc` for indexing by position and `loc` for indexing by labelled indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing by position\n",
    "bands_founded.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When slicing by labelled index, the last value specified is *included*, which differs from regular Python slicing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing by index\n",
    "bands_founded.loc[\"Zeppelin\" : \"Pink Floyd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that index 17 is included\n",
    "bands.loc[1:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for series (not for data frames), `loc` and just using bracket notation is identical: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[2:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both, `iloc` and `loc` can be used with arrays, which isn't possible in vanilla Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.iloc[[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.loc[[\"Beatles\", \"Pink Floyd\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, all these variants can also be used with boolean arrays, which we will soon find out to be very helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.loc[[True, False, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking and Filtering\n",
    "\n",
    "With pandas we can create boolean arrays that we can use to mask and filter a dataset. In the following expression, we'll create a new array that has \"True\" for every band formed after 1964:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = bands_founded > 1964\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses a technique called **broadcasting**. We can use broadcasting with various operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not particularly useful for this dataset..\n",
    "founding_months = bands_founded * 12\n",
    "founding_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a boolean mask to filter a series, as we've seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the mask to the original array\n",
    "# note that almost all of those operations return a new copy and don't modify in place\n",
    "bands_founded[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The short form here would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded[bands_founded > 1967]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring a Series\n",
    "\n",
    "There are various way we can explore a series. We can count the number of non-null values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = pd.Series([1962, 1960, 1968, 1965, 2012, None, 2016])\n",
    "numbers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the sum, mean, median of a series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get an overview of the statistical properties of a series: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that None/NaN values are ignored here. We can drop all NaN values if we desire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = numbers.dropna()\n",
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works also for non-numerical data. Of course, we get different measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other useful methods are asking for a specific quantile, the minimum, the maximum, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting \n",
    "\n",
    "We can sort a series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make the sorting descending: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_numbers = numbers.sort_values(ascending=False)\n",
    "sorted_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the indices remain the same! We can **reset the indices**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't specify drop to be true, the previous indices are preserved in a separte column\n",
    "sorted_numbers = sorted_numbers.reset_index(drop=True)\n",
    "sorted_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sort by the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix up the indices first\n",
    "new_sorted_numbers = numbers.sort_values()\n",
    "print(new_sorted_numbers)\n",
    "new_sorted_numbers.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a Function\n",
    "\n",
    "Often, we will want to apply a function to all values of a Series. We can do that with the [`map()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Convert an integer year into a date, assuming Jan 1 as day and month.\n",
    "def to_date(year):\n",
    "    return datetime.date(int(year), 1, 1)\n",
    "    \n",
    "new_sorted_numbers.map(to_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an incredibly powerful concept that you can use to modify series in sophisticated ways, similar to list comprehension. \n",
    "\n",
    "Another way to use the map function is to pass in a dictionary that is then applied to matching objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sorted_numbers.map({1965:1945, 2012:1999, 1968:\"What\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Pandas Series\n",
    "\n",
    "Create a new pandas series with the lists given below that contain NFL team names and the number of Super Bowl titles they won. Use the names as indices, the wins as the data.\n",
    "\n",
    " * Once the list is created, sort the series alphabetically by index. \n",
    " * Print an overview of the statistical properties of the series. What's the mean number of wins?\n",
    " * Filter out all teams that have won less than four Super Bowl titles\n",
    " * A football team has 45 players. Update the series so that instead of the number of titles, it reflects the number of Super Bowl rings given to the players. \n",
    " * Assume that each ring costs USD 30,000. Update the series so that it contains a string of the dollar amount including the \\$ sign. For the Steelers, for example, this would correspond to: \n",
    " ```\n",
    " Pittsburgh Steelers             $ 8100000\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [\"New England Patriots\",\n",
    "         \"Pittsburgh Steelers\",\n",
    "         \"Dallas Cowboys\",\n",
    "         \"San Francisco 49ers\",\n",
    "         \"Green Bay Packers\",\n",
    "         \"New York Giants\",\n",
    "         \"Denver Broncos\",\n",
    "         \"Oakland/Los Angeles Raiders\",\n",
    "         \"Washington Redskins\",\n",
    "         \"Miami Dolphins\",\n",
    "         \"Baltimore/Indianapolis Colts\",\n",
    "         \"Baltimore Ravens\"]\n",
    "wins = [6,6,5,5,4,4,3,3,3,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frames\n",
    "\n",
    "Before we look at dataframes, let's just load some data from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums = pd.read_csv(\"hit_albums.csv\")\n",
    "hit_albums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides the insanely powerful ['read_csv()'](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) method. Also see [the documentation](http://pandas.pydata.org/pandas-docs/stable/io.html) for more info on all I/O operations in pandas, including writing CSV files. \n",
    "\n",
    "You can pass a lot of arguments to the method, such as delimiter, quote-chars, etc., but for our case the default parameters just worked. \n",
    "\n",
    "We've also just created our first data frame! Let's look at data frames in detail next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data frame is a column-oriented data structure where each column is a pandas series.\n",
    "\n",
    "Here is a great [cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) for pandas functions. \n",
    "\n",
    "We've already loaded a data frame from file, but for completeness sake, let's create one in code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandInfo = pd.DataFrame({\n",
    "        \"Name\":[\"Led Zeppelin\", \"The Beatles\", \"Rolling Stones\", \"Radiohead\"],\n",
    "        \"No Members\":[4, 4, 4, 5],\n",
    "        \"No Albums\":[9, 12, 29 ,9]\n",
    "    })\n",
    "bandInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe was initialized with a dictonary of column headers as keys and column data as values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a series, a data frame has an index, which corresponds to the first column here. In this case the index was automatically generated, but as for the series, we could use explicit values for the index. \n",
    "\n",
    "We can access columns in a data frame, which returns a series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandInfo[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bandInfo[\"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And obviously, we can do all the things we've learned about to this column/series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous example used columns to create the data frame. We can also create a data frame from rows. This doesn't make a ton of sense in this example, but data could be available like this from your data source, like if you're parsing a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandInfo2 = pd.DataFrame([\n",
    "        {\"Name\":\"Led Zeppelin\", \"No Albums\":9, \"No Members\":4},\n",
    "        {\"Name\":\"The Beatles\", \"No Albums\":12, \"No Members\":4},\n",
    "        {\"Name\":\"Rolling Stones\", \"No Albums\":29, \"No Members\":4},\n",
    "        {\"Name\":\"Radiohead\", \"No Albums\":9, \"No Members\":5},\n",
    "    ])\n",
    "bandInfo2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a series has only one axis, a dataframe has two, one for the rows (the index or '0' axis), one for the columns (the column or '1' axis). We can check out these axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandInfo.axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data Frames\n",
    "\n",
    "You might have noticed that data frames are rendered in nice HTML tables within Jupyter Notebooks. For small data frames, just showing all the data makes sense, but for larger datasets, like our `hit_albums` dataset, plotting 70+ rows can be annoying, and for datasets with hundreds or thousands of rows it can be prohibitive. By default, a data frame only prints a limited number of elements (notice the `...` in row 5 of the output of `hit_albums` above – only the first 4 and last 4 are printed. \n",
    "\n",
    "When working with data, e.g., when transforming or loading a dataset, it is important to see the raw data, for example, to check if a transformation was done correctly. Often, however, it's sufficient to see a part of the data, e.g., the first couple of rows and/or the last couple of rows. We can do this with the `head()` and `tail()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head shows the first 5 rows of a datset\n",
    "hit_albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can specify how much to show\n",
    "hit_albums.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tail shows the last five rows in a datasaet\n",
    "hit_albums.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out the dimensions of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we learn that our dataset has 77 rows and 6 columns.\n",
    "\n",
    "We can also get more info about the dataset using the info method, which is especially helpful to see the data types of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for series, we can get a rough description of the numerical values of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see any descriptions of the columns of non-numerical type. We can, however, get a summary by directly accessing a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[\"Artist\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that Michael Jackson is the top artist in this list, with five albums. Are there other artists with multiple albums in the list? We can answer that question with the value_counts() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[\"Artist\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at whether the numerical columns in our data frame are correlated using the [`corr()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) method. By default, this calculates a Pearson correlation between the column, excluding NaN values. Not surprisingly, we see a rather strong correlation (0.81) between certified and claimed sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do transpose a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing Data Frames\n",
    "\n",
    "A common task is to create subsets of a dataframe. Check out the official [user guide for more info on this](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html).  \n",
    "\n",
    "Column access/slicing works by directly using brackets `[]` on the data frame. Row access/slicing works by using the `.loc[]` indexer. \n",
    "\n",
    "We can explicitly define the the **column(s)** we want by their lables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single column\n",
    "hit_albums[\"Artist\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an array of lables if we want multiple columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying multiple columns in an array\n",
    "hit_albums = hit_albums[[\"Artist\",\"Certified sales (millions)\", \"Claimed sales (millions)\"]]\n",
    "hit_albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing of columns requires the `iloc` operator\n",
    "\n",
    "This: \n",
    "```python\n",
    "hit_albums[\"Artist\":\"Genre\"]\n",
    "```\n",
    "Doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One break with the convention that rows have to be accessed via `loc` or `iloc` is simple numerical slicing. The documentation claims that's for convenience, since this is so common: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these access methods we can also update the order: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[[\"Certified sales (millions)\", \"Claimed sales (millions)\", \"Artist\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set a column to be the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed = hit_albums.set_index(\"Artist\")\n",
    "hit_albums_reindexed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing with `loc`\n",
    "\n",
    "We can retrieve **rows** and columns using the `loc` indexer by name. Depending on whether the label is unique or not, we get either a series or a data frame. \n",
    "\n",
    "Generally, `loc` is preferred over direct access via brackets. \n",
    "\n",
    "The general syntax is\n",
    "\n",
    "```\n",
    "df.loc[rows, columnns]\n",
    "```\n",
    "Here rows, columns can be explicit labels, lists of labels, or slicing operators. \n",
    "\n",
    "Here's a simple example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Meat Loaf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an example with multiple keys that returns a data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Michael Jackson\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second argument in the `loc` array can be used to access columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Michael Jackson\", \"Certified sales (millions)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example with a list of row labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[[\"Michael Jackson\", \"Meat Loaf\"], \"Certified sales (millions)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use slice operations. Remember, that slicing by label (`loc`) includes the last value, by index (`iloc`) does not. \n",
    "\n",
    "\n",
    "Note that this doesn't work if we use labels that have duplicates as indexers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Green Day\":\"Supertramp\"]\n",
    "\n",
    "# this wouldn't work\n",
    "# hit_albums_reindexed.loc[\"Green Day\":\"Michael Jackson\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be combined with slicing columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Green Day\":\"Supertramp\", [\"Certified sales (millions)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also slice columns with loc. Let's re-load the full dataset first:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums = pd.read_csv(\"hit_albums.csv\")\n",
    "full_hit_albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a slice containing all rows and the columns from Artist to Released: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[:,\"Artist\":\"Released\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a slice for the first 10 rows and columns Artists to Released: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[:10,\"Artist\":\"Released\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same thing using `iloc`, i.e., index based slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.iloc[0:10, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Of course, we can use broadcasting and filtering based on boolean masks just as we do for series.\n",
    "\n",
    "Here we boradcast an operation on a series and set it to a new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums[\"Certified sales\"] =  full_hit_albums[\"Certified sales (millions)\"] * 1000000\n",
    "full_hit_albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we filter out all of the albums that were released before 1990. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = full_hit_albums[\"Released\"] > 1990\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, short: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[full_hit_albums[\"Released\"] > 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Data Frames\n",
    "\n",
    "Very often, we want to aggregate data. Given the hit-albums dataset, for example, we might want to ask how many albums each artist in that list has sold in total. We can do these aggregations using the [group-by method](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html). \n",
    "\n",
    "But first, let's take care of some NAN values by running [`fillna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) on it. We use forward fill along the columns, so that the certified sales are filled into the claimed sales if necessary. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums = hit_albums.fillna(axis=1, method='ffill')\n",
    "hit_albums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a column to group by, for example, \"Artist\". We can look at the groups created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = hit_albums.groupby(\"Artist\")\n",
    "grouped.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the keys map to a set of indices. For example, Michael Jackson's albums are found at indices [0, 10, 16, 65, 66].\n",
    "\n",
    "Once we have created these groups, we can specify what to do with it.\n",
    "\n",
    "Pandas has a couple of built in functions to make this easy. For example, we can just call `sum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sum().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that we've summed up the data for each column. However, note that NaN plus some number is still NaN, which is treated as 0 here. So let's work with a slice of the dataframe instead. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we sort them, and have a nice result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sum().sort_values(\"Certified sales (millions)\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is the `count` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.count().sort_values(\"Certified sales (millions)\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A very generic solution is the `agg()` function, which we can pass a function to do things with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we pass the sum function, which calcualtes the sum of a list, to the group\n",
    "grouped.agg(sum).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass in numpy functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "grouped.agg(np.std).sort_values(\"Certified sales (millions)\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an aggregation with an in-line function definition where we still create the sum, but also multiply by a million. We use a [lambda expression](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions) to define the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg(lambda rows : sum([cell * 1000000 for cell in rows])).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda expressions are just a different way of defining a function in line, without assigning it a name. They only work for a single statement. \n",
    "\n",
    "Here is a simple lambda expression, which returns a function, which we assign to the variable add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = lambda a, b : a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's take this apart: \n",
    "\n",
    "```python\n",
    "[cell * 1000000 for cell in rows]\n",
    "```\n",
    "\n",
    "This part is a list comprehension, that takes an array `rows` and multiplies every element with 1,000,000. \n",
    "\n",
    "The surrounding `sum` is a call to the sum function, so adds up the values in the just modified array. \n",
    "\n",
    "And finally, the lambda expression packs all of this in a function. \n",
    "\n",
    "Here is a different, longer way to write this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumUpAndMultiplyByMillion(rows):\n",
    "    multiplied_rows = [cell * 1000000 for cell in rows]\n",
    "    summed_value = sum(multiplied_rows)\n",
    "    return summed_value\n",
    "\n",
    "grouped.agg(sumUpAndMultiplyByMillion).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Data Frames\n",
    "\n",
    "* Calculate the mean certified sales for all albums.\n",
    "* Create a new dataframe that only contains albums with more than 20 million certified sales.\n",
    "* Create a new dataframe based on the hit_albums dataset that only contains the artists that have at least two albums in the list.\n",
    "* Create a new dataframe that contains the aggregates sum of all certified sales for each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buit-in Plotting\n",
    "\n",
    "Dataframes have built-in plotting capabilities based on the [matplotlib](http://matplotlib.org/) library. We'll see more about plotting later - here we'll only use the buit-in capabilities of pandas. \n",
    "\n",
    "First, we have to import the matplotlib library, and tell Jupyter to display the images directly here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "# This next line tells jupyter to render the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can simply call the plot attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also selected certain columns using labelled indexes and then plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[\"Certified sales (millions)\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use bar-charts instead of line-charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[[\"Certified sales (millions)\", \"Claimed sales (millions)\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is a line chart. This doesn't make much sense, since it's mixing index of the row with sales. We're better off plotting only the two different sales figures.\n",
    "\n",
    "A better way to compare certified and claimed sales is a scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.plot.scatter(x=\"Certified sales (millions)\", y=\"Claimed sales (millions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a histogram: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.plot.hist(bins=12, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do more sophisticated plotting next time! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Dates\n",
    "\n",
    "Pandas is pretty good at working with dates. When you initially load a dataset, chances are the date will be provided as a string: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = pd.DataFrame({\n",
    "        \"Name\":[\"Joe Coder\", \"Roberta Hacker\", \"Ludmilla Designer\", \"Devin Opers\"],\n",
    "        \"Years Experience\":[4, 4, 4, 5],\n",
    "        \"Date Joined\":[\"2022-11-03\", \"2023-04-01\",\"2019-12-24\" ,\"2018-05-01\"]\n",
    "    })\n",
    "team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show column data types\n",
    "team.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`to_datetime()`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) function lets you parse dates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team[\"Date Joined\"] = pd.to_datetime(team[\"Date Joined\"])\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access individual elements of a date, you can use the [`dt` fields](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team[\"month joined\"] = team[\"Date Joined\"].dt.month\n",
    "team[\"quater joined\"] = team[\"Date Joined\"].dt.quarter\n",
    "team"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
